{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Base Model\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataa=[]\n",
    "training_labell=[]\n",
    "\n",
    "window=30\n",
    "stride=int(window/2)  \n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/3.Distance_DD/Training/Action_{}/*.txt'.format(k))):    \n",
    "        Files.append(file)\n",
    "\n",
    "    for m in range(len(Files)):\n",
    "        if m not in (3,7,13,17,23,27,33,37,43,47,53,57,63,67,73,77,83,87,93,97):\n",
    "            f = open(Files[m], 'r')\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp = df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p, 'float32')\n",
    "\n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))\n",
    "                training_dataa.append(new_mat)\n",
    "                training_labell.append(k)\n",
    "\n",
    "training_data_3=  training_dataa\n",
    "training_label = training_labell\n",
    "\n",
    "print(len(training_dataa))\n",
    "print(len(training_labell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = len(training_data_1[0])\n",
    "column = len(training_data_1[0][0])\n",
    "print(row)\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1 = np.array(training_data_1, 'float32')\n",
    "training_data_1 = training_data_1.reshape((len(training_data_1),row,column,1))\n",
    "print(training_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = np.array(training_data_2, 'float32')\n",
    "training_data_2 = training_data_2.reshape((len(training_data_2),row,column,1))\n",
    "print(training_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_3 = np.array(training_data_3, 'float32')\n",
    "training_data_3 = training_data_3.reshape((len(training_data_3),row,column,1))\n",
    "print(training_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "for i in range(len(training_data_1)):\n",
    "    img= np.dstack((training_data_1[i],training_data_2[i],training_data_3[i] ))\n",
    "    training_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For DISTANCE features\n",
    "training_data_dis = np.array(training_data,'float32' )\n",
    "training_data_dis = training_data_dis.reshape(len(training_data_dis),row,column,3)\n",
    "\n",
    "training_label=np.array(training_label)\n",
    "print(training_data_dis.shape)\n",
    "print(training_label.shape)\n",
    "print(type(training_data_dis))\n",
    "print(type(training_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataa=[]\n",
    "testing_labell=[]\n",
    "\n",
    "window = 30\n",
    "stride = int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    \n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/5.Angle_D/Training/Action_{}/*.txt'.format(k))):     \n",
    "        Files.append(file)\n",
    "         \n",
    "    for m in range(len(Files)):\n",
    "        if m in (3,7,13,17,23,27,33,37,43,47,53,57,63,67,73,77,83,87,93,97):\n",
    "            f = open(Files[m], 'r')\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp=df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p,'float32')\n",
    "\n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat)) \n",
    "                testing_dataa.append(new_mat)\n",
    "                testing_labell.append(k)\n",
    "testing_data_3 = testing_dataa          \n",
    "testing_label=testing_labell               \n",
    "\n",
    "print(len(testing_dataa))\n",
    "print(len(testing_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = len(testing_data_1[0])\n",
    "column = len(testing_data_1[0][0])\n",
    "print(row)\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_1 = np.array(testing_data_1, 'float32')\n",
    "testing_data_1 = testing_data_1.reshape((len(testing_data_1),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_2 = np.array(testing_data_2, 'float32')\n",
    "testing_data_2 = testing_data_2.reshape((len(testing_data_2),row,column,1))\n",
    "print(testing_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_3 = np.array(testing_data_3, 'float32')\n",
    "testing_data_3 = testing_data_3.reshape((len(testing_data_3),row,column,1))\n",
    "print(testing_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "for i in range(len(testing_data_1)):\n",
    "    img= np.dstack((testing_data_1[i],testing_data_2[i],testing_data_3[i]))\n",
    "    testing_data.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance Feature\n",
    "testing_data_dis = np.array(testing_data, 'float32')\n",
    "testing_data_dis = testing_data_dis.reshape((len(testing_data_dis),row,column,3))\n",
    "\n",
    "testing_label=np.array(testing_label)\n",
    "print(testing_data_dis.shape)\n",
    "print(testing_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Base Model\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout,BatchNormalization\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d_new_1.hdf5'\n",
    "os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data labels to categorical\n",
    "training_label = keras.utils.to_categorical(training_label, 7)\n",
    "testing_label= keras.utils.to_categorical(testing_label, 7)\n",
    "\n",
    "# print(training_label.shape)\n",
    "# print(testing_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_label.shape)\n",
    "print(testing_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best model with 3D skeleton data \n",
    "\n",
    "\n",
    "row = 30\n",
    "column = 360\n",
    "\n",
    "kinect_input = Input(shape=(row, column, 3))\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', \\\n",
    "           kernel_regularizer=l2(0.001))(kinect_input)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(7, activation = 'softmax')(x)\n",
    "\n",
    "base_model = Model(inputs = kinect_input, output = predictions)\n",
    "\n",
    "# mm = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr= 0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam,  metrics=['accuracy'])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                            monitor='val_acc',\n",
    "                            verbose=1,\n",
    "                            save_best_only=True,\n",
    "                            mode='max')\n",
    "\n",
    "history = base_model.fit([training_data_dis], \n",
    "                         training_label,\n",
    "                batch_size=32,\n",
    "                epochs=100,\n",
    "                verbose=1,\n",
    "                validation_data=([testing_data_dis], testing_label),\n",
    "                callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath)\n",
    "test_pur = base_model.predict([testing_data_dis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(testing_label)):\n",
    "    if np.argmax(testing_label[i]) == np.argmax(test_pur[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(testing_label))*100\n",
    "print('left_hand accuracy :', accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(history.history['acc'], history.history['val_acc'])\n",
    "for i in range(len(history.history['acc'])):\n",
    "    print(i,history.history['acc'][i],history.history['val_acc'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(history.history['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history.history['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(test_label_tf)):\n",
    "    y = np.argmax(test_label_tf[i])\n",
    "    y_true.append(y)\n",
    "\n",
    "for i in range(len(test_pur)):\n",
    "    y = np.argmax(test_pur[i]) #Make changes here\n",
    "    y_pred.append(y)\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cl_name = np.array(['Action-0','Action-1','Action-2','Action-3','Action-4','Action-5','Action-6'])\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for transfer learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataa=[]\n",
    "training_labell=[]\n",
    "\n",
    "window=30\n",
    "stride=int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/6.Angle_DD/Testing/subject_yuli/Action_{}/*.txt'.format(k))):\n",
    "        Files.append(file)\n",
    "    for m in range(len(Files)):\n",
    "        if m in (0,1): #unchanged\n",
    "            f = open(Files[m], 'r')\n",
    "#             print(f)\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp = df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p, 'float32')\n",
    "            \n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))\n",
    "                training_dataa.append(new_mat)\n",
    "                training_labell.append(k)\n",
    "                \n",
    "training_data_3 = training_dataa\n",
    "train_label = training_labell\n",
    "print(len(training_dataa))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = len(training_data_1[0])\n",
    "column = len(training_data_1[0][0])\n",
    "print(row)\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_1 = np.array(training_data_1, 'float32')\n",
    "training_data_1 = training_data_1.reshape((len(training_data_1),row,column,1))\n",
    "print(training_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_2 = np.array(training_data_2, 'float32')\n",
    "training_data_2 = training_data_2.reshape((len(training_data_2),row,column,1))\n",
    "print(training_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_3 = np.array(training_data_3, 'float32')\n",
    "training_data_3 = training_data_3.reshape((len(training_data_3),row,column,1))\n",
    "print(training_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(training_data_1)):\n",
    "    img= np.dstack((training_data_1[i],training_data_2[i],training_data_3[i]))\n",
    "    train_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tf = np.array(train_data,'float32')\n",
    "train_data_tf = train_data_tf.reshape(len(train_data_tf),30,360,3)\n",
    "\n",
    "train_label_tf=np.array(train_label) \n",
    "print(train_data_tf.shape)\n",
    "print(train_label_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataa=[]\n",
    "testing_labell=[]\n",
    "\n",
    "window = 30\n",
    "stride = int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "#     for file in sorted(glob.glob('./ALR_2/Copy_2/1.Distance/Testing/subject_chen/Action_{}/*.txt'.format(k))):\n",
    "#     for file in sorted(glob.glob('./ALR_2/Copy_2/3.Distance_D/Testing/subject_chen/Action_{}/*.txt'.format(k))):\n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/6.Angle_DD/Testing/subject_yuli/Action_{}/*.txt'.format(k))):\n",
    "\n",
    "        \n",
    "        Files.append(file)\n",
    "    for m in range(len(Files)):    \n",
    "        if m in (5,6,7,8,9,15,16,17,18,19): #original test set\n",
    "#         if m in (19,): #original test set            \n",
    "            f = open(Files[m], 'r')\n",
    "#             print(f)\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp=df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p,'float32')\n",
    "\n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))      \n",
    "                testing_dataa.append(new_mat)\n",
    "                testing_labell.append(k)                       \n",
    "                \n",
    "testing_data_3= testing_dataa\n",
    "test_label = testing_labell\n",
    "\n",
    "print(len(testing_dataa))\n",
    "print(len(testing_labell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = len(testing_dataa[0])\n",
    "column = len(testing_dataa[0][0])\n",
    "print(row)\n",
    "print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_1 = np.array(testing_data_1, 'float32')\n",
    "testing_data_1 = testing_data_1.reshape((len(testing_data_1),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_2 = np.array(testing_data_2, 'float32')\n",
    "testing_data_2 = testing_data_2.reshape((len(testing_data_2),row,column,1))\n",
    "print(testing_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_3 = np.array(testing_data_3, 'float32')\n",
    "testing_data_3 = testing_data_3.reshape((len(testing_data_3),row,column,1))\n",
    "print(testing_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = []\n",
    "for i in range(len(testing_data_1)):\n",
    "    img= np.dstack((testing_data_1[i],testing_data_2[i],testing_data_3[i]))\n",
    "    test_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tf = np.array(test_data, 'float32') \n",
    "test_data_tf = test_data_tf.reshape((len(test_data_tf),30,column,3))\n",
    "\n",
    "test_label_tf=np.array(test_label)\n",
    "print(test_data_tf.shape)\n",
    "print(test_label_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the categorical labels into one_hot_coding\n",
    "# train_label_tf = keras.utils.to_categorical(train_label_tf, 7)\n",
    "test_label_tf = keras.utils.to_categorical(test_label_tf, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_label_tf.shape)\n",
    "# print(train_label_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best model with 3D skeleton data \n",
    "\n",
    "\n",
    "row = row\n",
    "column = column\n",
    "\n",
    "kinect_input = Input(shape=(row, column, 3))\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', \\\n",
    "           kernel_regularizer=l2(0.001))(kinect_input)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(7, activation = 'softmax')(x)\n",
    "\n",
    "base_model = Model(inputs = kinect_input, output = predictions)\n",
    "\n",
    "# mm = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr= 0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam,  metrics=['accuracy'])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature #1: Dis_2_01234101112131420212223.hdf5\n",
    "Feature #2: Dis_D_1_01234101112131420212223.hdf5\n",
    "Feature #3: Dis_DD_1_012341011121314202122232425.hdf5\n",
    "Feature #4: Ang_1_0123410.hdf5\n",
    "Feature #5: Ang_D_1_01234101112131420212223.hdf5\n",
    "Feature #6: Ang_DD_1_01.hdf5\n",
    "ang_3d_new_1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath= 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d.hdf5'\n",
    "os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath)\n",
    "test_pur = base_model.predict([test_data_tf],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(test_label_tf)):\n",
    "    if np.argmax(test_label_tf[i]) == np.argmax(test_pur[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(test_label_tf))*100\n",
    "print('accuracy :', accuracy_1)\n",
    "print(test_label_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_2 = test_pur\n",
    "dis_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dis_1.shape)\n",
    "print(dis_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on individual model\n",
    "all_list = [dis_1, dis_2]\n",
    "all_list_name = ['dis_1','dis_2']\n",
    "\n",
    "\n",
    "for j in range(len(all_list)):\n",
    "    match_1 = 0\n",
    "    for i in range(len(test_label_tf)):\n",
    "        if np.argmax(test_label_tf[i]) == np.argmax(all_list[j][i]):\n",
    "            match_1+=1\n",
    "    accuracy_1 = (match_1/len(test_label_tf))*100\n",
    "    print(all_list_name[j],':',accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prediction ## For 2 sensor FUSION\n",
    "\n",
    "prediction_max = []\n",
    "for i in range(len(test_label_tf)):\n",
    "    x = np.vstack((dis_1[i],dis_2[i]))\n",
    "\n",
    "    m = np.max(x, axis=0)\n",
    "    prediction_max.append(m)\n",
    "prediction_max = np.array(prediction_max)\n",
    "\n",
    "prediction_avg = []\n",
    "for i in range(len(test_label_tf)):\n",
    "    x = np.vstack((dis_1[i],dis_2[i]))\n",
    "\n",
    "    x = np.average(x, axis=0)\n",
    "    prediction_avg.append(x)\n",
    "prediction_avg = np.array(prediction_avg)\n",
    "\n",
    "pred_product = []\n",
    "for i in range(len(test_label_tf)):\n",
    "    \n",
    "    x = np.vstack((dis_1[i],dis_2[i]))\n",
    "\n",
    "    o = np.product(x, axis = 0)\n",
    "    pred_product.append(o)\n",
    " \n",
    "pred_product = np.array(pred_product)\n",
    "\n",
    "\n",
    "print(len(prediction_max))\n",
    "print(len(prediction_avg))\n",
    "print(len(pred_product))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Fusion Method\n",
    "\n",
    "list_1 = [prediction_max, prediction_avg, pred_product]\n",
    "list_2 = ['prediction_max','prediction_avg', 'pred_product']\n",
    "\n",
    "for j in range(len(list_1)):\n",
    "    correct = 0\n",
    "    for i in range(len(test_label_tf)):\n",
    "        if np.argmax(list_1[j][i]) == np.argmax(test_label_tf[i]): #make a change here\n",
    "            correct+=1\n",
    "    accuracy = (correct/test_label_tf.shape[0])*100\n",
    "    print(list_2[j],': {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = 0\n",
    "bal_1 = []\n",
    "bal_2 = []\n",
    "# bal_3 = []\n",
    "for i in range(len(test_label_tf)):\n",
    "#     print(np.argmax(test_label_mis[i]))\n",
    "#     m+=1\n",
    "#     print(np.argmax(test_pur_5[i]))\n",
    "    bal_1.append(test_pur[i])\n",
    "    bal_2.append(np.argmax(test_label_tf[i]))\n",
    "#     bal_3.append(np.argmax(test_pur_5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Gpr_dis.csv',bal_1, delimiter=',')\n",
    "np.savetxt('Gr_Tr.csv',bal_2, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_iter_act = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d_yul_1.hdf5'\n",
    "os.path.exists(filepath_iter_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Applying Transfer learning, 11 is the  basic\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "for layer in base_model.layers[:10]:\n",
    "        layer.trainable = False\n",
    "for layer in base_model.layers[10:]:  \n",
    "        layer.trainable = True\n",
    "        \n",
    "base_model = Model(inputs=base_model.input, outputs=predictions)  \n",
    "\n",
    "adam = keras.optimizers.Adam(lr= 0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam,  metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath_iter_act,\n",
    "                               monitor='val_acc',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "\n",
    "history = base_model.fit(train_data_tf, train_label_tf, \n",
    "              batch_size=16, \n",
    "              epochs=100, \n",
    "              verbose=1, \n",
    "              validation_data=(test_data_tf, test_label_tf),\n",
    "              callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath_iter_act)\n",
    "test_pur = base_model.predict([test_data_tf],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(test_label_tf)):\n",
    "    if np.argmax(test_label_tf[i]) == np.argmax(test_pur[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(test_label_tf))*100\n",
    "print('accuracy :', accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [prediction_max, prediction_avg, pred_product]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(test_label_tf)):\n",
    "    y = np.argmax(test_label_tf[i])\n",
    "    y_true.append(y)\n",
    "\n",
    "for i in range(len(pred_product)):\n",
    "    y = np.argmax(pred_product[i]) #Make changes here\n",
    "    y_pred.append(y)\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cl_name = np.array(['Action-0','Action-1','Action-2','Action-3','Action-4','Action-5','Action-6'])\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(base_model.layers)):\n",
    "    print(i, base_model.layers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with 1 or 2 experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with 1 or 2 experiments\n",
    "testing_dataa=[]\n",
    "testing_labell=[]\n",
    "\n",
    "window = 30\n",
    "stride = int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    \n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/6.Angle_DD/Testing/subject_yuli/Action_{}/*.txt'.format(k))):\n",
    "        Files.append(file)\n",
    "         \n",
    "    for m in range(len(Files)):\n",
    "        if m in (28,29):\n",
    "            f = open(Files[m], 'r')\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp=df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p,'float32')\n",
    "\n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))            \n",
    "                testing_dataa.append(new_mat)\n",
    "                testing_labell.append(k)\n",
    "testing_data_234_3=testing_dataa          \n",
    "testing_label_234=testing_labell           \n",
    "\n",
    "print(len(testing_dataa))\n",
    "print(len(testing_labell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_1 = np.array(testing_data_234_1, 'float32')\n",
    "testing_data_1 = testing_data_1.reshape((len(testing_data_1),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_2 = np.array(testing_data_234_2, 'float32')\n",
    "testing_data_2 = testing_data_2.reshape((len(testing_data_2),row,column,1))\n",
    "print(testing_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_3 = np.array(testing_data_234_3, 'float32')\n",
    "testing_data_3 = testing_data_3.reshape((len(testing_data_3),row,column,1))\n",
    "print(testing_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_234 = []\n",
    "for i in range(len(testing_data_1)):\n",
    "    img= np.dstack((testing_data_1[i],testing_data_2[i],testing_data_3[i]))\n",
    "    testing_data_234.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance Feature\n",
    "testing_data_dis_ts = np.array(testing_data_234, 'float32')\n",
    "testing_data_dis_ts = testing_data_dis_ts.reshape((len(testing_data_dis_ts),row,column,3))\n",
    "\n",
    "testing_label_ts=np.array(testing_label_234)\n",
    "print(testing_data_dis_ts.shape)\n",
    "print(testing_label_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d_yul_0123410111213142021222324252627.hdf5'\n",
    "os.path.exists(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath)\n",
    "test_pur_234 = base_model.predict([testing_data_dis_ts], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data labels to categorical\n",
    "# training_label = keras.utils.to_categorical(training_label, 7)\n",
    "testing_label_ts= keras.utils.to_categorical(testing_label_ts, 7)\n",
    "print(testing_label_ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(testing_label_ts)):\n",
    "    if np.argmax(testing_label_ts[i]) == np.argmax(test_pur_234[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(testing_label_ts))*100\n",
    "print('left_hand accuracy:', accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(testing_label_ts)):\n",
    "    y = np.argmax(testing_label_ts[i])\n",
    "    y_true.append(y)\n",
    "\n",
    "for i in range(len(test_pur_234)):\n",
    "    y = np.argmax(test_pur_234[i]) #Make changes here\n",
    "    y_pred.append(y)\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl_name = np.array(['Action-0','Action-1','Action-2','Action-3','Action-4','Action-5','Action-6'])\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing idea with misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataa=[]\n",
    "training_labell=[]\n",
    "\n",
    "window=30\n",
    "stride=int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/6.Angle_DD/Testing/subject_yuli/Action_{}/*.txt'.format(k))):\n",
    "        Files.append(file)\n",
    "    for m in range(len(Files)):\n",
    "        if m in (0,1): #unchanged\n",
    "            print(Files[m])\n",
    "            f = open(Files[m], 'r')\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp = df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p, 'float32')\n",
    "            \n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))\n",
    "                training_dataa.append(new_mat)\n",
    "                training_labell.append(k)     \n",
    "\n",
    "train_data_miss_3 = training_dataa\n",
    "train_label_miss = training_labell\n",
    "\n",
    "print(len(training_dataa))\n",
    "print(len(training_labell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_1 = np.array(train_data_miss_1, 'float32')\n",
    "testing_data_1 = testing_data_1.reshape((len(testing_data_1),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_2 = np.array(train_data_miss_2, 'float32')\n",
    "testing_data_2 = testing_data_2.reshape((len(testing_data_2),row,column,1))\n",
    "print(testing_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_3 = np.array(train_data_miss_3, 'float32')\n",
    "testing_data_3 = testing_data_3.reshape((len(testing_data_3),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_miss = []\n",
    "for i in range(len(testing_data_1)):\n",
    "    img= np.dstack((testing_data_1[i],testing_data_2[i],testing_data_3[i]))\n",
    "    train_data_miss.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "for i in range(len(test_pur_234)):\n",
    "    if np.argmax(testing_label_ts[i]) != np.argmax(test_pur_234[i]):\n",
    "        x = np.argmax(testing_label_ts[i])\n",
    "        if x in (0,1,2,3,4,5,6):\n",
    "            print(i, np.argmax(testing_label_ts[i]),np.argmax(test_pur_234[i]))\n",
    "            m+=1\n",
    "print('Total misclassified samples:', m)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Current BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_miss))\n",
    "print(len(train_label_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_pur_234)): ##identified missalpled from 234\n",
    "    if np.argmax(testing_label_ts[i]) != np.argmax(test_pur_234[i]):\n",
    "        x = np.argmax(testing_label_ts[i])\n",
    "        if x in (0,1,2,3,4,5,6):\n",
    "            train_data_miss.append(testing_data_234[i])       \n",
    "            train_label_miss.append(np.argmax(testing_label_ts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data_miss))\n",
    "print(len(train_label_miss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current_BEST MODEL\n",
    "train_data_mis = np.array(train_data_miss,'float32')\n",
    "train_data_mis = train_data_mis.reshape(len(train_data_mis),row,column,3)\n",
    "\n",
    "train_label_mis=np.array(train_label_miss)\n",
    "print(train_data_mis.shape)\n",
    "print(train_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data labels to categorical\n",
    "train_label_mis = keras.utils.to_categorical(train_label_mis, 7)\n",
    "\n",
    "print(train_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataa=[]\n",
    "testing_labell=[]\n",
    "\n",
    "window = 30\n",
    "stride = int(window/2)\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "    for file in sorted(glob.glob('./ALR_2/Copy_2/6.Angle_DD/Testing/subject_yuli/Action_{}/*.txt'.format(k))):\n",
    "        Files.append(file)\n",
    "    for m in range(len(Files)):    \n",
    "        if m in (5,6,7,8,9,15,16,17,18,19):\n",
    "#         if m in (19,):            \n",
    "            f = open(Files[m], 'r')\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp=df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p,'float32')                \n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                where_are_NaNs = np.isnan(new_mat)\n",
    "                new_mat[where_are_NaNs]=1\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))         \n",
    "                testing_dataa.append(new_mat)\n",
    "                testing_labell.append(k)                             \n",
    "                \n",
    "test_data_3= testing_dataa\n",
    "test_label = testing_labell\n",
    "\n",
    "print(len(testing_dataa))\n",
    "print(len(testing_labell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row, column = 30,360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_1 = np.array(test_data_1, 'float32')\n",
    "testing_data_1 = testing_data_1.reshape((len(testing_data_1),row,column,1))\n",
    "print(testing_data_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_2 = np.array(test_data_2, 'float32')\n",
    "testing_data_2 = testing_data_2.reshape((len(testing_data_2),row,column,1))\n",
    "print(testing_data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_3 = np.array(test_data_3, 'float32')\n",
    "testing_data_3 = testing_data_3.reshape((len(testing_data_3),row,column,1))\n",
    "print(testing_data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(testing_data_1)):\n",
    "    img= np.dstack((testing_data_1[i],testing_data_2[i],testing_data_3[i]))\n",
    "    test_data.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_mis = np.array(test_data, 'float32')\n",
    "test_data_mis = test_data_mis.reshape((len(test_data_mis),row,column,3))\n",
    "\n",
    "test_label_mis=np.array(test_label)\n",
    "print(test_data_mis.shape)\n",
    "print(test_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data labels to categorical\n",
    "test_label_mis= keras.utils.to_categorical(test_label_mis, 7)\n",
    "print(test_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data_mis.shape)\n",
    "print(train_label_mis.shape)\n",
    "\n",
    "print(test_data_mis.shape)\n",
    "print(test_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d_yul_0123410111213142021222324252627.hdf5'\n",
    "os.path.exists(filepath_new_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath_new_mis)\n",
    "test_pur_5 = base_model.predict([test_data_mis],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(test_label_mis)):\n",
    "    if np.argmax(test_label_mis[i]) == np.argmax(test_pur_5[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(test_label_mis))*100\n",
    "print('accuracy :', accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\ang_3d_yul_01234101112131420212223242526272829.hdf5'\n",
    "os.path.exists(filepath_new_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Applying Transfer learning, 11 is the  basic\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "for layer in base_model.layers[:10]:\n",
    "        layer.trainable = False\n",
    "for layer in base_model.layers[10:]:  \n",
    "        layer.trainable = True\n",
    "        \n",
    "base_model = Model(inputs=base_model.input, outputs=predictions)  \n",
    "\n",
    "adam = keras.optimizers.Adam(lr= 0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam,  metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath_new_mis,\n",
    "                               monitor='val_acc',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)\n",
    "# class_weight = {0: 1, 1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1}\n",
    "\n",
    "history = base_model.fit(train_data_mis, train_label_mis, \n",
    "              batch_size=16, \n",
    "              epochs=100, \n",
    "              verbose=1, \n",
    "              validation_data=(test_data_mis, test_label_mis),\n",
    "              callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Angle_DD_111_8p.hdf5'\n",
    "# filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Ang_DD_1_01.hdf5'\n",
    "\n",
    "# filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Dis_DD_2_in_mis_01234.hdf5'\n",
    "# filepath_new_mis = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Dis_3_01234101112131420212223242526272829.hdf5'\n",
    "\n",
    "os.path.exists(filepath_new_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature #1: Dis_2_01234101112131420212223242526272829.hdf5\n",
    "Feature #2: Dis_D_1_01234101112131420212223.hdf5\n",
    "Feature #3: Dis_DD_1_01234101112131420212223242526272829.hdf5\n",
    "Feature #4: Ang_1_0123410.hdf5\n",
    "Feature #5: Ang_D_1_01234101112131420212223.hdf5\n",
    "Feature #6: Ang_DD_1_01.hdf5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(filepath_new_mis)\n",
    "test_pur_5 = base_model.predict([test_data_mis],batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_label_mis.shape)\n",
    "# print(test_pur_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_1 = 0\n",
    "for i in range(len(test_label_mis)):\n",
    "    if np.argmax(test_label_mis[i]) == np.argmax(test_pur_5[i]):\n",
    "        match_1+=1\n",
    "accuracy_1 = (match_1/len(test_label_mis))*100\n",
    "print('accuracy :', accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = 0\n",
    "bal_1 = []\n",
    "bal_2 = []\n",
    "bal_3 = []\n",
    "for i in range(len(test_label_mis)):\n",
    "#     print(np.argmax(test_label_mis[i]))\n",
    "#     m+=1\n",
    "#     print(np.argmax(test_pur_5[i]))\n",
    "    bal_1.append(test_pur_5[i])\n",
    "    bal_2.append(np.argmax(test_label_mis[i]))\n",
    "    bal_3.append(np.argmax(test_pur_5[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pur_5[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bal_1), len(bal_2), len(bal_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Gpr_dis.csv',bal_1, delimiter=',')\n",
    "np.savetxt('Gr_Tr.csv',bal_2, delimiter=',')\n",
    "# np.savetxt('bal_3.csv',bal_3, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(test_label_mis)):\n",
    "    y = np.argmax(test_label_mis[i])\n",
    "    y_true.append(y)\n",
    "\n",
    "for i in range(len(test_pur_5)):\n",
    "    y = np.argmax(test_pur_5[i]) #Make changes here\n",
    "    y_pred.append(y)\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cl_name = np.array(['Action-0','Action-1','Action-2','Action-3','Action-4','Action-5','Action-6'])\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix')\n",
    "\n",
    "#     print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cl_name, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging the model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best model with 3D skeleton data \n",
    "\n",
    "\n",
    "row = 32\n",
    "column = 120\n",
    "\n",
    "kinect_input = Input(shape=(row, column, 1))\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', \\\n",
    "           kernel_regularizer=l2(0.001))(kinect_input)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(64, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv2D(128, (3,3), activation='relu',padding='same',kernel_initializer='he_normal', kernel_regularizer=l2(0.001))(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "predictions = Dense(7, activation = 'softmax')(x)\n",
    "\n",
    "base_model = Model(inputs = kinect_input, output = predictions)\n",
    "\n",
    "# mm = keras.optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr= 0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "base_model.compile(loss='categorical_crossentropy', optimizer=adam,  metrics=['accuracy'])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataa=[]\n",
    "testing_labell=[]\n",
    "\n",
    "window = 32\n",
    "stride = 16\n",
    "\n",
    "for k in range(7):\n",
    "    Files=[]\n",
    "#     for file in sorted(glob.glob('/floyd/home/Modified_LH_IMU_new/11_person_data/Action_{}/*.txt'.format(k))):\n",
    "    for file in sorted(glob.glob('./ALR/Copy/26.Angle_DD/subject-1/Action_{}/*.txt'.format(k))):\n",
    "        Files.append(file)\n",
    "    for m in range(len(Files)):    \n",
    "#         if k in (0,1,2,4,5) and m not in (0,1):\n",
    "        if m in (5,6,7,8,9,15,16, 17,18,19):\n",
    "            f = open(Files[m], 'r')\n",
    "#             print(Files[m])\n",
    "            df = f.readlines()\n",
    "            f.close()\n",
    "            p=[]\n",
    "            for i in range(len(df)):\n",
    "                temp=df[i].split()\n",
    "                p.append(temp)\n",
    "            p = np.array(p,'float32')\n",
    "\n",
    "            for i in range(0,len(p)-stride, stride):\n",
    "                new_mat = p[i:i+window]\n",
    "                new_mat = (new_mat-np.mean(new_mat))/(np.max(new_mat)-np.min(new_mat))        \n",
    "                testing_dataa.append(new_mat)\n",
    "                testing_labell.append(k)                             \n",
    "                \n",
    "test_data = testing_dataa\n",
    "test_label = testing_labell\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_mis = np.array(test_data, 'float32') \n",
    "test_data_mis = test_data_mis.reshape((len(test_data_mis),row,120,1))\n",
    "\n",
    "test_label_mis=np.array(test_label)\n",
    "print(test_data_mis.shape)\n",
    "print(test_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the data labels to categorical\n",
    "# train_label_mis = keras.utils.to_categorical(train_label_mis, 7)\n",
    "test_label_mis= keras.utils.to_categorical(test_label_mis, 7)\n",
    "# print(train_label_mis.shape)\n",
    "print(test_label_mis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Feature #1: Dis_1_01234101112131420212223.hdf5\n",
    "Feature #2: Dis_D_1_01234101112131420212223.hdf5\n",
    "Feature #3: Dis_DD_1_012341011121314202122232425.hdf5\n",
    "Feature #4: Ang_1_0123410.hdf5\n",
    "Feature #5: Ang_D_1_01234101112131420212223.hdf5\n",
    "Feature #6: Ang_DD_1_01.hdf5\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Dis_1_01234101112131420212223.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "distance = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Dis_D_1_01234101112131420212223.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "distance_D = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Dis_DD_1_012341011121314202122232425.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "distance_DD = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Ang_1_0123410.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "angle = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Ang_D_1_01234101112131420212223.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "angle_D = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:\\\\Users\\\\ma2nq\\\\Desktop\\\\python\\\\Kinect_data\\\\journal\\\\Ang_DD_1_01.hdf5'\n",
    "base_model.load_weights(filepath)\n",
    "angle_DD = base_model.predict([test_data_mis], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on individual model\n",
    "all_list = [distance_n,distance_D_n,distance_DD_n,angle_n,angle_D_n,angle_DD_n]\n",
    "all_list_name = ['distance','distance_D','distance_DD','angle','angle_D','angle_DD']\n",
    "\n",
    "# all_list = [distance,distance_D,distance_DD]\n",
    "# all_list_name = ['distance','distance_D','distance_DD']\n",
    "for j in range(len(all_list)):\n",
    "    match_1 = 0\n",
    "    for i in range(len(test_label_mis)):\n",
    "        if np.argmax(test_label_mis[i]) == np.argmax(all_list[j][i]):\n",
    "            match_1+=1\n",
    "    accuracy_1 = (match_1/len(test_label_mis))*100\n",
    "    print(all_list_name[j],':',accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Prediction ## For 2 sensor FUSION\n",
    "\n",
    "prediction_max = []\n",
    "for i in range(len(distance)):\n",
    "    x = np.vstack((distance_n[i],distance_D_n[i],distance_DD_n[i],angle_n[i],angle_D_n[i],angle_DD_n[i]))\n",
    "    m = np.max(x, axis=0)\n",
    "    prediction_max.append(m)\n",
    "prediction_max = np.array(prediction_max)\n",
    "\n",
    "prediction_avg = []\n",
    "for i in range(len(distance)):\n",
    "    x = np.vstack((distance_n[i],distance_D_n[i],distance_DD_n[i],angle_n[i],angle_D_n[i],angle_DD_n[i]))\n",
    "    x = np.average(x, axis=0)\n",
    "    prediction_avg.append(x)\n",
    "prediction_avg = np.array(prediction_avg)\n",
    "\n",
    "pred_product = []\n",
    "for i in range(len(distance)):\n",
    "    x = np.vstack((distance_n[i],distance_D_n[i],distance_DD_n[i],angle_n[i],angle_D_n[i],angle_DD_n[i]))\n",
    "\n",
    "    o = np.product(x, axis = 0)\n",
    "    pred_product.append(o)\n",
    "    \n",
    "pred_product = np.array(pred_product)\n",
    "\n",
    "\n",
    "print(len(prediction_max))\n",
    "print(len(prediction_avg))\n",
    "print(len(pred_product))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle_DD_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on Fusion Method\n",
    "\n",
    "list_1 = [prediction_max, prediction_avg, pred_product]\n",
    "list_2 = ['prediction_max','prediction_avg', 'pred_product']\n",
    "\n",
    "for j in range(len(list_1)):\n",
    "    correct = 0\n",
    "    for i in range(len(distance)):\n",
    "        if np.argmax(list_1[j][i]) == np.argmax(test_label_mis[i]): #make a change here\n",
    "            correct+=1\n",
    "    accuracy = (correct/distance.shape[0])*100\n",
    "    print(list_2[j],':' ,accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
